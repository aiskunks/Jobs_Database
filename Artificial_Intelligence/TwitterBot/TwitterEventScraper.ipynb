{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb360353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from dataclasses import dataclass, field\n",
    "import dataclasses\n",
    "from typing import List\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import stanza\n",
    "import emoji\n",
    "import html\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03a6a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAHpjjAEAAAAAn%2BCYkmL02wnLmmY1BEn0%2FhZDcAw%3D1yCPthd5oyDAmQdEGowVHmOWmunSflrAK4nWrxneNwYEZ3VDZT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b37c7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cdaeaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '(\"data science\" OR \"artificial intelligence\" OR \"machine learning\" OR \"Big Data\" OR \"Deep Learning\" OR ml OR ai) (context:131.1303989823011606528 OR context:131.1495104058285125642) lang:en has:links -is:retweet'\n",
    "pages = tweepy.Paginator(client.search_recent_tweets, query=query, expansions=['author_id'], tweet_fields=['context_annotations','created_at','author_id','entities','public_metrics','text'], user_fields=['username','name','location','created_at'], limit=400, max_results=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24b76090",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class User():\n",
    "    id: str = ''\n",
    "    name: str = ''\n",
    "    username: str = ''\n",
    "    location: str = ''\n",
    "    dateJoined: str = ''\n",
    "\n",
    "@dataclass\n",
    "class EventTweetData():\n",
    "    id: str = ''\n",
    "    user: User = None\n",
    "    description: str = ''\n",
    "    datePosted: str = ''\n",
    "    likeCount: int = 0\n",
    "    links: List[str] = field(default_factory=list)\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "    derivedTags: List[str] = field(default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "891969b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emoji_free_text(text):\n",
    "    return emoji.replace_emoji(text, replace='', version=-1)\n",
    "\n",
    "def remove_special_char(text):\n",
    "    string = html.unescape(text)\n",
    "    string = html.unescape(string)\n",
    "    return re.sub('&lt;/?[a-z]+&gt;', '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3867b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventDataModels = []\n",
    "\n",
    "for page in pages:\n",
    "\n",
    "    userList = dict()\n",
    "    tweets = page\n",
    "\n",
    "    for user in tweets.includes['users']:\n",
    "        userModel = User()\n",
    "        userModel.id = user['id']\n",
    "        userModel.name = user['name']\n",
    "        userModel.username = user['username']\n",
    "        userModel.location = user['location']\n",
    "        userModel.dateJoined = user['created_at'].strftime('%Y-%m-%d')\n",
    "        userList[userModel.id] = userModel\n",
    "\n",
    "    for tweet in tweets.data:\n",
    "        eventTweetModel = EventTweetData()\n",
    "        eventTweetModel.id = tweet['id']\n",
    "        eventTweetModel.user = userList[tweet['author_id']]\n",
    "        eventTweetModel.datePosted = tweet['created_at'].strftime('%Y-%m-%d')\n",
    "        eventTweetModel.description = tweet['text']\n",
    "        eventTweetModel.likeCount = tweet['public_metrics']['like_count']\n",
    "        urlList = list()\n",
    "        for url in tweet['entities']['urls']:\n",
    "            if re.search('twitter', url['expanded_url']):\n",
    "                continue\n",
    "            urlList.append(url['expanded_url'])\n",
    "        if len(urlList) == 0: \n",
    "            continue\n",
    "        eventTweetModel.links = urlList\n",
    "        tagList = list()\n",
    "        if ('hashtags' in tweet['entities']):\n",
    "            for hashtag in tweet['entities']['hashtags']:\n",
    "                tagList.append(hashtag['tag'])\n",
    "        tagList = list(set(tagList))\n",
    "        eventTweetModel.tags = tagList\n",
    "        eventDataModels.append(eventTweetModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55b30e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 17:47:48 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-11-13 17:47:48 INFO: Use device: cpu\n",
      "2022-11-13 17:47:48 INFO: Loading: tokenize\n",
      "2022-11-13 17:47:48 INFO: Loading: ner\n",
      "2022-11-13 17:47:50 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner', download_method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da33328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtags(text):\n",
    "    return re.sub(\"#[A-Za-z0-9_]+\",\"\", text.replace('-', ''))\n",
    "\n",
    "for model in eventDataModels:\n",
    "    processed_data = nlp(remove_hashtags(model.description))\n",
    "    for sent in processed_data.sentences:\n",
    "        for ent in sent.ents:\n",
    "            if(ent.type == 'ORG'):\n",
    "                for tag in ent.text.split('\\n'):\n",
    "                    model.derivedTags.append(tag.strip())\n",
    "            elif(ent.type == 'TITLE'):\n",
    "                model.title = ent.text\n",
    "    model.derivedTags = list(set(model.derivedTags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70a5fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonMappedData = dict()\n",
    "jsonEventDictList = []\n",
    "for model in eventDataModels:\n",
    "    jsonEventDictList.append(dataclasses.asdict(model))\n",
    "jsonMappedData['twitterEventData'] = jsonEventDictList\n",
    "\n",
    "with open('twitterEventData'+datetime.now().strftime('%m_%d_%Y')+'.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(jsonMappedData, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8d3f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(\n",
    "    user='root', password='test@123', host='127.0.0.1', database='ai_jobs_database'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53d63794",
   "metadata": {},
   "outputs": [],
   "source": [
    "userInsertQuery = \"\"\" INSERT IGNORE INTO twitter_user(user_id, name, user_name, location, date_joined)\n",
    "                      VALUES (%s, %s, %s, %s, %s);\n",
    "                  \"\"\"\n",
    "eventTweetInsertQuery = \"\"\"INSERT IGNORE INTO event_tweets(tweet_id, user_id, description, date_posted, like_count)\n",
    "                           VALUES (%s, %s, %s, %s, %s);\n",
    "                        \"\"\"\n",
    "twitterTagInsertQuery = \"\"\"INSERT IGNORE INTO twitter_tag(tag_name, tweet_id)\n",
    "                           VALUES (%s, %s)\n",
    "                        \"\"\"\n",
    "derivedTagInsertQuery = \"\"\"INSERT IGNORE INTO derived_tag(der_tag_name, tweet_id)\n",
    "                           VALUES (%s, %s)\n",
    "                        \"\"\"\n",
    "urlInsertQuery = \"\"\"INSERT IGNORE INTO tweet_url(url, tweet_id)\n",
    "                    VALUES (%s, %s)\n",
    "                 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9e88018",
   "metadata": {},
   "outputs": [],
   "source": [
    "userData = []\n",
    "eventTweetData = []\n",
    "twitterTagData = []\n",
    "derivedTagData = []\n",
    "urlData = []\n",
    "for model in eventDataModels:\n",
    "    userData.append((model.user.id, model.user.name, model.user.username, model.user.location, model.user.dateJoined))\n",
    "    eventTweetData.append((model.id, model.user.id, model.description, model.datePosted, model.likeCount))\n",
    "    for tag in model.tags:\n",
    "        twitterTagData.append((tag, model.id))\n",
    "    for tag in model.derivedTags:\n",
    "        derivedTagData.append((tag, model.id))\n",
    "    for link in model.links:\n",
    "        urlData.append((link, model.id))\n",
    "\n",
    "try:\n",
    "    cursor.executemany(userInsertQuery, userData)\n",
    "    cursor.executemany(eventTweetInsertQuery, eventTweetData)\n",
    "    cursor.executemany(twitterTagInsertQuery, twitterTagData)\n",
    "    cursor.executemany(derivedTagInsertQuery, derivedTagData)\n",
    "    cursor.executemany(urlInsertQuery, urlData)\n",
    "    conn.commit()\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(e)\n",
    "    \n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
